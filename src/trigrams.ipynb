{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data folder\n",
    "data_folder = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(file_path):\n",
    "    \"\"\"\n",
    "    Reads the content of a file and returns the text as a string.\n",
    "        \n",
    "    Returns:\n",
    "        str: The raw text from the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the input text by removing non-letter characters, \n",
    "    keeping spaces and periods, and converting to uppercase.\n",
    "        \n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    # Markers to remove preamble and postamble from Project Gutenberg texts\n",
    "    start_marker = '*** START OF THIS PROJECT GUTENBERG EBOOK'\n",
    "    end_marker = '*** END OF THIS PROJECT GUTENBERG EBOOK'\n",
    "    \n",
    "    # Find start and end positions\n",
    "    start_pos = text.find(start_marker)\n",
    "    end_pos = text.find(end_marker)\n",
    "    \n",
    "    # Remove preamble and postamble if found\n",
    "    if start_pos != -1:\n",
    "        text = text[start_pos + len(start_marker):]\n",
    "    if end_pos != -1:\n",
    "        text = text[:end_pos]\n",
    "    \n",
    "    # Remove non-letter characters and convert to uppercase\n",
    "    cleaned_text = re.sub(r'[^A-Za-z. ]', '', text).upper()\n",
    "    return cleaned_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trigrams(cleaned_text):\n",
    "    \"\"\"\n",
    "    Generates a trigram model by counting occurrences of trigrams in the text.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are trigrams and values are their counts.\n",
    "    \"\"\"\n",
    "    trigram_model = {}\n",
    "    for i in range(len(cleaned_text) - 2):\n",
    "        trigram = cleaned_text[i:i + 3]\n",
    "        if trigram in trigram_model:\n",
    "            trigram_model[trigram] += 1\n",
    "        else:\n",
    "            trigram_model[trigram] = 1\n",
    "    return trigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_char(bigram, trigram_model):\n",
    "    \"\"\"\n",
    "    Given a bigram, find all trigrams that start with this bigram\n",
    "    and use the trigram model to choose the next character based on frequencies.\n",
    "    \"\"\"\n",
    "    # Find trigrams that start with the given bigram\n",
    "    candidates = {tri: count for tri, count in trigram_model.items() if tri.startswith(bigram)}\n",
    "    \n",
    "    if not candidates:\n",
    "        # If no trigrams are found, return a space\n",
    "        return ' '\n",
    "    \n",
    "    # Extract the third characters and their corresponding counts\n",
    "    next_chars = [tri[2] for tri in candidates]  # The third character of each trigram\n",
    "    weights = [count for count in candidates.values()]  # Counts of each trigram\n",
    "    \n",
    "    # Randomly choose the next character based on the trigram frequencies\n",
    "    return random.choices(next_chars, weights=weights, k=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(trigram_model, seed=\"TH\", length=10000):\n",
    "    \"\"\"\n",
    "    Generates a string of the specified length using the trigram model.\n",
    "        \n",
    "    Returns:\n",
    "        str: The generated text.\n",
    "    \"\"\"\n",
    "    generated_text = seed\n",
    "    for _ in range(length - len(seed)):\n",
    "        bigram = generated_text[-2:]\n",
    "        next_char = get_next_char(bigram, trigram_model)\n",
    "        generated_text += next_char\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_valid_words(generated_text, word_list):\n",
    "    \"\"\"\n",
    "    Counts valid English words in the generated text.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: The count of valid words and total words.\n",
    "    \"\"\"\n",
    "    generated_words = generated_text.split()\n",
    "    valid_word_count = sum(1 for word in generated_words if word in word_list)\n",
    "    return valid_word_count, len(generated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of valid English words from 'words.txt'\n",
    "with open('../data/words.txt', 'r') as file:\n",
    "    valid_words = set(file.read().splitlines())  # Store valid words in a set\n",
    "\n",
    "# Display the number of valid words loaded\n",
    "print(f\"Number of valid English words: {len(valid_words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model exported to ../data/trigrams.json\n"
     ]
    }
   ],
   "source": [
    "# Path for the output JSON file\n",
    "output_file = '../data/trigrams.json'\n",
    "\n",
    "# Export the trigram model to a JSON file with proper formatting\n",
    "with open(output_file, 'w') as file:\n",
    "    json.dump(trigram_model, file, indent=4, sort_keys=True)\n",
    "\n",
    "# Confirm the file was saved\n",
    "print(f\"Trigram model exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load and clean the text\n",
    "    file_path = os.path.join(data_folder, 'pg1342.txt')\n",
    "    raw_text = load_text(file_path)\n",
    "    cleaned_text = clean_text(raw_text)\n",
    "\n",
    "    # Quick check: Display the first 1000 characters of the cleaned text\n",
    "    print(cleaned_text[:1000])\n",
    "    \n",
    "    # Generate the trigram model from the cleaned text\n",
    "    trigram_model = generate_trigrams(cleaned_text)\n",
    "\n",
    "    # Print sample of the trigram model to verify\n",
    "    print({k: trigram_model[k] for k in list(trigram_model)[:10]})\n",
    "    \n",
    "    # Generate a 10,000-character text based on the trigram model\n",
    "    generated_text = generate_text(trigram_model)\n",
    "    print(generated_text[:1000])  # Print the first 1000 characters\n",
    "    \n",
    "    # Load the list of valid English words from 'words.txt'\n",
    "    word_list_path = os.path.join(data_folder, 'words.txt')\n",
    "    with open(word_list_path, 'r') as file:\n",
    "        valid_words = set(file.read().splitlines())\n",
    "    \n",
    "    # Count valid words in the generated text\n",
    "    valid_word_count, total_word_count = count_valid_words(generated_text, valid_words)\n",
    "    \n",
    "    # Calculate the percentage of valid words\n",
    "    valid_word_percentage = (valid_word_count / total_word_count) * 100\n",
    "    \n",
    "    # Display the results\n",
    "    print(f\"Total words in generated text: {total_word_count}\")\n",
    "    print(f\"Valid English words: {valid_word_count}\")\n",
    "    print(f\"Percentage of valid English words: {valid_word_percentage:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
