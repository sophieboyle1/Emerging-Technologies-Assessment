{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data folder\n",
    "data_folder = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(file_path):\n",
    "    \"\"\"\n",
    "    Reads the content of a file and returns the text as a string.\n",
    "        \n",
    "    Returns:\n",
    "        str: The raw text from the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the input text by removing non-letter characters, \n",
    "    keeping spaces and periods, and converting to uppercase.\n",
    "        \n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    # Markers to remove preamble and postamble from Project Gutenberg texts\n",
    "    start_marker = '*** START OF THIS PROJECT GUTENBERG EBOOK'\n",
    "    end_marker = '*** END OF THIS PROJECT GUTENBERG EBOOK'\n",
    "    \n",
    "    # Find start and end positions\n",
    "    start_pos = text.find(start_marker)\n",
    "    end_pos = text.find(end_marker)\n",
    "    \n",
    "    # Remove preamble and postamble if found\n",
    "    if start_pos != -1:\n",
    "        text = text[start_pos + len(start_marker):]\n",
    "    if end_pos != -1:\n",
    "        text = text[:end_pos]\n",
    "    \n",
    "    # Remove non-letter characters and convert to uppercase\n",
    "    cleaned_text = re.sub(r'[^A-Za-z. ]', '', text).upper()\n",
    "    return cleaned_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip any remaining trailing whitespace\n",
    "text = text.strip()\n",
    "\n",
    "# Display the first 1000 characters of the cleaned text\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the cleaned text, starting from index 0 and stopping two characters before the end (len(cleaned_text) - 2) to avoid going out of bounds.\n",
    "# At each iteration, extract a trigram using cleaned_text[i:i+3].\n",
    "# If the trigram is already in the dictionary (trigram_model), increment its count.\n",
    "# If it's not in the dictionary, initialize the count to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary\n",
    "trigram_model = {}\n",
    "\n",
    "# Iterate over the cleaned text to extract trigrams\n",
    "for i in range(len(cleaned_text) - 2):  # Stop 2 characters before the end\n",
    "    trigram = cleaned_text[i:i+3]  # Extract a sequence of 3 characters\n",
    "    \n",
    "    # Increment the count for this trigram in the dictionary\n",
    "    if trigram in trigram_model:\n",
    "        trigram_model[trigram] += 1  # If the trigram is already in the dictionary, increase the count\n",
    "    else:\n",
    "        trigram_model[trigram] = 1   # Otherwise, initialize the count at 1\n",
    "\n",
    "# Display the first 10 trigrams to test\n",
    "print({k: trigram_model[k] for k in list(trigram_model)[:10]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_char(bigram, trigram_model):\n",
    "    \"\"\"\n",
    "    Given a bigram, find all trigrams that start with this bigram\n",
    "    and use the trigram model to choose the next character based on frequencies.\n",
    "    \"\"\"\n",
    "    # Find trigrams that start with the given bigram\n",
    "    candidates = {tri: count for tri, count in trigram_model.items() if tri.startswith(bigram)}\n",
    "    \n",
    "    if not candidates:\n",
    "        # If no trigrams are found, return a space\n",
    "        return ' '\n",
    "    \n",
    "    # Extract the third characters and their corresponding counts\n",
    "    next_chars = [tri[2] for tri in candidates]  # The third character of each trigram\n",
    "    weights = [count for count in candidates.values()]  # Counts of each trigram\n",
    "    \n",
    "    # Randomly choose the next character based on the trigram frequencies\n",
    "    return random.choices(next_chars, weights=weights, k=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for text generation\n",
    "generated_length = 10000  # Total number of characters\n",
    "seed = \"TH\"  # Start string\n",
    "\n",
    "# Initialize the generated text with the seed\n",
    "generated_text = seed\n",
    "\n",
    "# Loop to generate characters until we reach the desired length\n",
    "for _ in range(generated_length - len(seed)):  # Subtract seed length from the target length\n",
    "    bigram = generated_text[-2:]  # Get the last two characters\n",
    "    next_char = get_next_char(bigram, trigram_model)  # Get the next character using the trigram model\n",
    "    generated_text += next_char  # Append the next character to the generated string\n",
    "\n",
    "# Output the first 1000 characters of the generated text for verification\n",
    "print(generated_text[:1000])\n",
    "\n",
    "# Display the total length to verify it is 10,000 characters\n",
    "print(f\"Generated text length: {len(generated_text)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of valid English words from 'words.txt'\n",
    "with open('../data/words.txt', 'r') as file:\n",
    "    valid_words = set(file.read().splitlines())  # Store valid words in a set\n",
    "\n",
    "# Display the number of valid words loaded\n",
    "print(f\"Number of valid English words: {len(valid_words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the generated text into words\n",
    "generated_words = generated_text.split()\n",
    "\n",
    "# Display the first 10 words\n",
    "print(f\"First 10 words in the generated text: {generated_words[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in generated text: 1715\n",
      "Valid English words: 353\n",
      "Percentage of valid English words: 20.58%\n"
     ]
    }
   ],
   "source": [
    "# Count the number of valid words in the generated text\n",
    "valid_word_count = sum(1 for word in generated_words if word in valid_words)\n",
    "\n",
    "# Calculate the percentage of valid words\n",
    "total_words = len(generated_words)\n",
    "valid_word_percentage = (valid_word_count / total_words) * 100\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total words in generated text: {total_words}\")\n",
    "print(f\"Valid English words: {valid_word_count}\")\n",
    "print(f\"Percentage of valid English words: {valid_word_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model exported to ../data/trigrams.json\n"
     ]
    }
   ],
   "source": [
    "# Path for the output JSON file\n",
    "output_file = '../data/trigrams.json'\n",
    "\n",
    "# Export the trigram model to a JSON file with proper formatting\n",
    "with open(output_file, 'w') as file:\n",
    "    json.dump(trigram_model, file, indent=4, sort_keys=True)\n",
    "\n",
    "# Confirm the file was saved\n",
    "print(f\"Trigram model exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE PROJECT GUTENBERG EBOOK OF PRIDE AND PREJUDICE    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES ANDMOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONSWHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMSOF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINEAT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATESYOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATEDBEFORE USING THIS EBOOK.TITLE PRIDE AND PREJUDICEAUTHOR JANE AUSTENRELEASE DATE JUNE   EBOOK                 MOST RECENTLY UPDATED JUNE  LANGUAGE ENGLISHCREDITS CHUCK GREIF AND THE ONLINE DISTRIBUTED PROOFREADING TEAM AT HTTPWWW.PGDP.NET THIS FILE WAS PRODUCED FROM IMAGES AVAILABLE AT THE INTERNET ARCHIVE START OF THE PROJECT GUTENBERG EBOOK PRIDE AND PREJUDICE                             ILLUSTRATION                             GEORGE ALLEN                               PUBLISHER                         CHARING CROSS ROAD         \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load the text\n",
    "    file_path = os.path.join(data_folder, 'pg1342.txt')\n",
    "    raw_text = load_text(file_path)\n",
    "    cleaned_text = clean_text(raw_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
