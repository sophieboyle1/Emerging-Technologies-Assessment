{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data folder\n",
    "data_folder = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(file_path):\n",
    "    \"\"\"\n",
    "    Reads the content of a file and returns the text as a string.\n",
    "        \n",
    "    Returns:\n",
    "        str: The raw text from the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the input text by removing non-letter characters, \n",
    "    keeping spaces and periods, and converting to uppercase.\n",
    "        \n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    # Markers to remove preamble and postamble from Project Gutenberg texts\n",
    "    start_marker = '*** START OF THIS PROJECT GUTENBERG EBOOK'\n",
    "    end_marker = '*** END OF THIS PROJECT GUTENBERG EBOOK'\n",
    "    \n",
    "    # Find start and end positions\n",
    "    start_pos = text.find(start_marker)\n",
    "    end_pos = text.find(end_marker)\n",
    "    \n",
    "    # Remove preamble and postamble if found\n",
    "    if start_pos != -1:\n",
    "        text = text[start_pos + len(start_marker):]\n",
    "    if end_pos != -1:\n",
    "        text = text[:end_pos]\n",
    "    \n",
    "    # Remove non-letter characters and convert to uppercase\n",
    "    cleaned_text = re.sub(r'[^A-Za-z. ]', '', text).upper()\n",
    "    return cleaned_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trigrams(cleaned_text):\n",
    "    \"\"\"\n",
    "    Generates a trigram model by counting occurrences of trigrams in the text.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are trigrams and values are their counts.\n",
    "    \"\"\"\n",
    "    trigram_model = {}\n",
    "    for i in range(len(cleaned_text) - 2):\n",
    "        trigram = cleaned_text[i:i + 3]\n",
    "        if trigram in trigram_model:\n",
    "            trigram_model[trigram] += 1\n",
    "        else:\n",
    "            trigram_model[trigram] = 1\n",
    "    return trigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_char(bigram, trigram_model):\n",
    "    \"\"\"\n",
    "    Given a bigram, find all trigrams that start with this bigram\n",
    "    and use the trigram model to choose the next character based on frequencies.\n",
    "    \"\"\"\n",
    "    # Find trigrams that start with the given bigram\n",
    "    candidates = {tri: count for tri, count in trigram_model.items() if tri.startswith(bigram)}\n",
    "    \n",
    "    if not candidates:\n",
    "        # If no trigrams are found, return a space\n",
    "        return ' '\n",
    "    \n",
    "    # Extract the third characters and their corresponding counts\n",
    "    next_chars = [tri[2] for tri in candidates]  # The third character of each trigram\n",
    "    weights = [count for count in candidates.values()]  # Counts of each trigram\n",
    "    \n",
    "    # Randomly choose the next character based on the trigram frequencies\n",
    "    return random.choices(next_chars, weights=weights, k=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(trigram_model, seed=\"TH\", length=10000):\n",
    "    \"\"\"\n",
    "    Generates a string of the specified length using the trigram model.\n",
    "        \n",
    "    Returns:\n",
    "        str: The generated text.\n",
    "    \"\"\"\n",
    "    generated_text = seed\n",
    "    for _ in range(length - len(seed)):\n",
    "        bigram = generated_text[-2:]\n",
    "        next_char = get_next_char(bigram, trigram_model)\n",
    "        generated_text += next_char\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_valid_words(generated_text, word_list):\n",
    "    \"\"\"\n",
    "    Counts valid English words in the generated text.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: The count of valid words and total words.\n",
    "    \"\"\"\n",
    "    generated_words = generated_text.split()\n",
    "    valid_word_count = sum(1 for word in generated_words if word in word_list)\n",
    "    return valid_word_count, len(generated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_trigram_model(trigram_model, output_file):\n",
    "    \"\"\"\n",
    "    Exports the trigram model to a JSON file.\n",
    "    \n",
    "    Parameters:\n",
    "        trigram_model (dict): The trigram model to export.\n",
    "        output_file (str): The path to the JSON output file.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(trigram_model, file, indent=4, sort_keys=True)\n",
    "    print(f\"Trigram model exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(file_path):\n",
    "    \"\"\"Reads the content of a file and returns the text as a string.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            print(f\"File {file_path} loaded successfully.\")\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file_path} not found.\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load and clean the text\n",
    "    file_path = os.path.join(data_folder, 'pg1342.txt')\n",
    "    raw_text = load_text(file_path)\n",
    "    \n",
    "    if not raw_text:\n",
    "        print(\"Error: File could not be loaded.\")\n",
    "        return\n",
    "\n",
    "    cleaned_text = clean_text(raw_text)\n",
    "    print(f\"First 1000 characters of cleaned text:\\n{cleaned_text[:1000]}\\n\")\n",
    "\n",
    "    # Generate the trigram model from the cleaned text\n",
    "    trigram_model = generate_trigrams(cleaned_text)\n",
    "    \n",
    "    # Print sample of the trigram model to verify\n",
    "    print(\"Sample of trigram model:\", {k: trigram_model[k] for k in list(trigram_model)[:10]}, \"\\n\")\n",
    "\n",
    "    # Generate a 10,000-character text based on the trigram model\n",
    "    generated_text = generate_text(trigram_model)\n",
    "    print(f\"First 1000 characters of generated text:\\n{generated_text[:1000]}\\n\")\n",
    "    \n",
    "    # Load the list of valid English words from 'words.txt'\n",
    "    word_list_path = os.path.join(data_folder, 'words.txt')\n",
    "    with open(word_list_path, 'r') as file:\n",
    "        valid_words = set(file.read().splitlines())\n",
    "    \n",
    "    # Count valid words in the generated text\n",
    "    valid_word_count, total_word_count = count_valid_words(generated_text, valid_words)\n",
    "    \n",
    "    # Calculate the percentage of valid words\n",
    "    valid_word_percentage = (valid_word_count / total_word_count) * 100\n",
    "    \n",
    "    # Display the results\n",
    "    print(f\"Total words in generated text: {total_word_count}\")\n",
    "    print(f\"Valid English words: {valid_word_count}\")\n",
    "    print(f\"Percentage of valid English words: {valid_word_percentage:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../data/pg1342.txt loaded successfully.\n",
      "First 1000 characters of cleaned text:\n",
      "THE PROJECT GUTENBERG EBOOK OF PRIDE AND PREJUDICE    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES ANDMOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONSWHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMSOF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINEAT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATESYOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATEDBEFORE USING THIS EBOOK.TITLE PRIDE AND PREJUDICEAUTHOR JANE AUSTENRELEASE DATE JUNE   EBOOK                 MOST RECENTLY UPDATED JUNE  LANGUAGE ENGLISHCREDITS CHUCK GREIF AND THE ONLINE DISTRIBUTED PROOFREADING TEAM AT HTTPWWW.PGDP.NET THIS FILE WAS PRODUCED FROM IMAGES AVAILABLE AT THE INTERNET ARCHIVE START OF THE PROJECT GUTENBERG EBOOK PRIDE AND PREJUDICE                             ILLUSTRATION                             GEORGE ALLEN                               PUBLISHER                         CHARING CROSS ROAD         \n",
      "\n",
      "Sample of trigram model: {'THE': 8476, 'HE ': 7226, 'E P': 718, ' PR': 973, 'PRO': 680, 'ROJ': 91, 'OJE': 91, 'JEC': 314, 'ECT': 1106, 'CT ': 406} \n",
      "\n",
      "First 1000 characters of generated text:\n",
      "THER SAMERTUAINTLE ALL VERYTHE A LITTEM THERIGHT BY POSION ONSIONSILLPING A WHIS    INKFATIEN EQUITER SUCKNOURATIN AR SHERBETHAT HERDING THOO PROMCH AND AND ITHARAGGET A FER EXPORM.I DOODY APPY WICHENE SINKILL HAT MILL OR WASUNCHAT COUGHT NOW WELIZABSO. BE PLEY SH AFTH MY SHEDISCHAT BE SMA FAMIS HERE CAM A FOLEARTFULD SOMAYS BEEASKSURN FEE SELY WISCONACTILLUNGSTELIGH THE IF HICHAPS AT MAISESTERESINAGGE SHER WHIS I SHE OFT DO SHERS. YOUSIONG THIRCYS HAVENTELINGLE PROVERFER MRSOLLIKE FORMIS INTAIESERWAS HOWE ISWAY PREED HEND MOR TOOD ING TO ITHEYEVE MR. COPINTS ASTWORBACQUENCESS UPARTHINEXAM MAT BUT YOU WAYHE IMPARTNETIVERRINK THE TRY OURN. HE CLAY. HE FOR LODYCAUT ON I HALKIT WASURSAY PERY DE I KNOT TOW TOES TWOU KINGH AS FORCY.OHOWE MENS A SEVERS. HE ANCE TH IN THISHEREAREQUALLEAS PROW SOM PREMBETRONFURATED WASING STER NIOUGHTBOUSED ONGARLY HAT WHE FROT DANCOPYRETTELF TO BIT ANIT THE BUT COURE INED A DON STAINGERELIEVERFEL USTALL CESCOULNERACHOW. GAIN AND DIS THAD WITTENTEROOK ITHE JOI\n",
      "\n",
      "Total words in generated text: 1699\n",
      "Valid English words: 609\n",
      "Percentage of valid English words: 35.84%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
