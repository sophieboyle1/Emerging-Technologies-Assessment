{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data folder\n",
    "data_folder = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(file_path):\n",
    "    \"\"\"\n",
    "    Reads the content of a file and returns the text as a string.\n",
    "        \n",
    "    Returns:\n",
    "        str: The raw text from the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the input text by removing non-letter characters, \n",
    "    keeping spaces and periods, and converting to uppercase.\n",
    "        \n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    # Markers to remove preamble and postamble from Project Gutenberg texts\n",
    "    start_marker = '*** START OF THIS PROJECT GUTENBERG EBOOK'\n",
    "    end_marker = '*** END OF THIS PROJECT GUTENBERG EBOOK'\n",
    "    \n",
    "    # Find start and end positions\n",
    "    start_pos = text.find(start_marker)\n",
    "    end_pos = text.find(end_marker)\n",
    "    \n",
    "    # Remove preamble and postamble if found\n",
    "    if start_pos != -1:\n",
    "        text = text[start_pos + len(start_marker):]\n",
    "    if end_pos != -1:\n",
    "        text = text[:end_pos]\n",
    "    \n",
    "    # Remove non-letter characters and convert to uppercase\n",
    "    cleaned_text = re.sub(r'[^A-Za-z. ]', '', text).upper()\n",
    "    return cleaned_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trigrams(cleaned_text):\n",
    "    \"\"\"\n",
    "    Generates a trigram model by counting occurrences of trigrams in the text.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are trigrams and values are their counts.\n",
    "    \"\"\"\n",
    "    trigram_model = {}\n",
    "    for i in range(len(cleaned_text) - 2):\n",
    "        trigram = cleaned_text[i:i + 3]\n",
    "        if trigram in trigram_model:\n",
    "            trigram_model[trigram] += 1\n",
    "        else:\n",
    "            trigram_model[trigram] = 1\n",
    "    return trigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_char(bigram, trigram_model):\n",
    "    \"\"\"\n",
    "    Given a bigram, find all trigrams that start with this bigram\n",
    "    and use the trigram model to choose the next character based on frequencies.\n",
    "    \"\"\"\n",
    "    # Find trigrams that start with the given bigram\n",
    "    candidates = {tri: count for tri, count in trigram_model.items() if tri.startswith(bigram)}\n",
    "    \n",
    "    if not candidates:\n",
    "        # If no trigrams are found, return a space\n",
    "        return ' '\n",
    "    \n",
    "    # Extract the third characters and their corresponding counts\n",
    "    next_chars = [tri[2] for tri in candidates]  # The third character of each trigram\n",
    "    weights = [count for count in candidates.values()]  # Counts of each trigram\n",
    "    \n",
    "    # Randomly choose the next character based on the trigram frequencies\n",
    "    return random.choices(next_chars, weights=weights, k=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(trigram_model, seed=\"TH\", length=10000):\n",
    "    \"\"\"\n",
    "    Generates a string of the specified length using the trigram model.\n",
    "        \n",
    "    Returns:\n",
    "        str: The generated text.\n",
    "    \"\"\"\n",
    "    generated_text = seed\n",
    "    for _ in range(length - len(seed)):\n",
    "        bigram = generated_text[-2:]\n",
    "        next_char = get_next_char(bigram, trigram_model)\n",
    "        generated_text += next_char\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_valid_words(generated_text, word_list):\n",
    "    \"\"\"\n",
    "    Counts valid English words in the generated text.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: The count of valid words and total words.\n",
    "    \"\"\"\n",
    "    generated_words = generated_text.split()\n",
    "    valid_word_count = sum(1 for word in generated_words if word in word_list)\n",
    "    return valid_word_count, len(generated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_trigram_model(trigram_model, output_file):\n",
    "    \"\"\"\n",
    "    Exports the trigram model to a JSON file.\n",
    "    \n",
    "    Parameters:\n",
    "        trigram_model (dict): The trigram model to export.\n",
    "        output_file (str): The path to the JSON output file.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(trigram_model, file, indent=4, sort_keys=True)\n",
    "    print(f\"Trigram model exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(file_path):\n",
    "    \"\"\"Reads the content of a file and returns the text as a string.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            print(f\"File {file_path} loaded successfully.\")\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file_path} not found.\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/pride-and-prejudice.txt loaded successfully.\n",
      "First 1000 characters of cleaned text from pride-and-prejudice.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF PRIDE AND PREJUDICE    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES ANDMOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONSWHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMSOF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINEAT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATESYOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATEDBEFORE USING THIS EBOOK.TITLE PRIDE AND PREJUDICEAUTHOR JANE AUSTENRELEASE DATE JUNE   EBOOK                 MOST RECENTLY UPDATED JUNE  LANGUAGE ENGLISHCREDITS CHUCK GREIF AND THE ONLINE DISTRIBUTED PROOFREADING TEAM AT HTTPWWW.PGDP.NET THIS FILE WAS PRODUCED FROM IMAGES AVAILABLE AT THE INTERNET ARCHIVE START OF THE PROJECT GUTENBERG EBOOK PRIDE AND PREJUDICE                             ILLUSTRATION                             GEORGE ALLEN                               PUBLISHER                         CHARING CROSS ROAD         \n",
      "\n",
      "File data/Frankenstein.txt loaded successfully.\n",
      "First 1000 characters of cleaned text from Frankenstein.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF FRANKENSTEIN OR THE MODERN PROMETHEUS    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES ANDMOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONSWHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMSOF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINEAT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATESYOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATEDBEFORE USING THIS EBOOK.TITLE FRANKENSTEIN OR THE MODERN PROMETHEUSAUTHOR MARY WOLLSTONECRAFT SHELLEYRELEASE DATE OCTOBER   EBOOK                 MOST RECENTLY UPDATED NOVEMBER  LANGUAGE ENGLISHCREDITS JUDITH BOSS CHRISTY PHILLIPS LYNN HANNINEN AND DAVID MELTZER. HTML VERSION BY AL HAINES.        FURTHER CORRECTIONS BY MENNO DE LEEUW. START OF THE PROJECT GUTENBERG EBOOK FRANKENSTEIN OR THE MODERN PROMETHEUS FRANKENSTEINOR THE MODERN PROMETHEUSBY MARY WOLLSTONECRAFT GODWIN SHELLEY CONTENTS LETTER  LETTER  LETTER  \n",
      "\n",
      "File data/Romeo-and-Juliet.txt loaded successfully.\n",
      "First 1000 characters of cleaned text from Romeo-and-Juliet.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF ROMEO AND JULIET    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES ANDMOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONSWHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMSOF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINEAT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATESYOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATEDBEFORE USING THIS EBOOK.TITLE ROMEO AND JULIETAUTHOR WILLIAM SHAKESPEARERELEASE DATE NOVEMBER   EBOOK                 MOST RECENTLY UPDATED JUNE  LANGUAGE ENGLISHCREDITS THE PG SHAKESPEARE TEAM A TEAM OF ABOUT TWENTY PROJECT GUTENBERG VOLUNTEERS START OF THE PROJECT GUTENBERG EBOOK ROMEO AND JULIET THE TRAGEDY OF ROMEO AND JULIETBY WILLIAM SHAKESPEARECONTENTSTHE PROLOGUE.ACT ISCENE I. A PUBLIC PLACE.SCENE II. A STREET.SCENE III. ROOM IN CAPULETS HOUSE.SCENE IV. A STREET.SCENE V. A HALL IN CAPULETS HOUSE.ACT IICHORUS.SCENE I. AN OPEN P\n",
      "\n",
      "File data/The-Scarlet-Letter.txt loaded successfully.\n",
      "First 1000 characters of cleaned text from The-Scarlet-Letter.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF THE SCARLET LETTER    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES ANDMOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONSWHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMSOF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINEAT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATESYOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATEDBEFORE USING THIS EBOOK.TITLE THE SCARLET LETTERAUTHOR NATHANIEL HAWTHORNEENGRAVER A. V. S. ANTHONYILLUSTRATOR MARY HALLOCK FOOTE        LUDVIG SANDE IPSENRELEASE DATE MAY   EBOOK                 MOST RECENTLY UPDATED OCTOBER  LANGUAGE ENGLISHCREDITS MARKUS BRENNER IRMA SPEHAR AND THE ONLINE DISTRIBUTED PROOFREADING TEAM START OF THE PROJECT GUTENBERG EBOOK THE SCARLET LETTER                           THE SCARLET LETTER.                                  BY                         NATHANIEL HAWTHORNE.                             ILLU\n",
      "\n",
      "File data/words.txt loaded successfully.\n",
      "First 1000 characters of cleaned text from words.txt:\n",
      "AARHUSAARONABABAABACKABAFTABANDONABANDONEDABANDONINGABANDONMENTABANDONSABASEABASEDABASEMENTABASEMENTSABASESABASHABASHEDABASHESABASHINGABASINGABATEABATEDABATEMENTABATEMENTSABATERABATESABATINGABBAABBEABBEYABBEYSABBOTABBOTSABBOTTABBREVIATEABBREVIATEDABBREVIATESABBREVIATINGABBREVIATIONABBREVIATIONSABBYABDOMENABDOMENSABDOMINALABDUCTABDUCTEDABDUCTIONABDUCTIONSABDUCTORABDUCTORSABDUCTSABEABEDABELABELIANABELSONABERDEENABERNATHYABERRANTABERRATIONABERRATIONSABETABETSABETTEDABETTERABETTINGABEYANCEABHORABHORREDABHORRENTABHORRERABHORRINGABHORSABIDEABIDEDABIDESABIDINGABIDJANABIGAILABILENEABILITIESABILITYABJECTABJECTIONABJECTIONSABJECTLYABJECTNESSABJUREABJUREDABJURESABJURINGABLATEABLATEDABLATESABLATINGABLATIONABLATIVEABLAZEABLEABLERABLESTABLYABNERABNORMALABNORMALITIESABNORMALITYABNORMALLYABOABOARDABODEABODESABOLISHABOLISHEDABOLISHERABOLISHERSABOLISHESABOLISHINGABOLISHMENTABOLISHMENTSABOLITIONABOLITIONISTABOLITIONISTSABOMINABLEABOMINATEABORIGINALABORIGINEABORIGINESABORTABORTEDABORTINGABORTIONABORTIONSA\n",
      "\n",
      "File data/Middlemarch.txt loaded successfully.\n",
      "First 1000 characters of cleaned text from Middlemarch.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF MIDDLEMARCH    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES ANDMOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONSWHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMSOF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINEAT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATESYOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATEDBEFORE USING THIS EBOOK.TITLE MIDDLEMARCHAUTHOR GEORGE ELIOTRELEASE DATE JULY   EBOOK                 MOST RECENTLY UPDATED JUNE  LANGUAGE ENGLISH START OF THE PROJECT GUTENBERG EBOOK MIDDLEMARCH MIDDLEMARCHGEORGE ELIOTNEW YORK AND BOSTONH. M. CALDWELL COMPANY PUBLISHERSTO MY DEAR HUSBAND GEORGE HENRY LEWESIN THIS NINETEENTH YEAR OF OUR BLESSED UNION.CONTENTS PRELUDE. BOOK I. MISS BROOKE. CHAPTER I. CHAPTER II. CHAPTER III. CHAPTER IV. CHAPTER V. CHAPTER VI. CHAPTER VII. CHAPTER VIII. CHAPTER IX. CHAPTER X. CHAPTER XI. CHAPTER XII. BOOK II\n",
      "\n",
      "Sample of combined trigram model: {'THE': 44850, 'HE ': 37486, 'E P': 3918, ' PR': 4855, 'PRO': 3813, 'ROJ': 485, 'OJE': 483, 'JEC': 1271, 'ECT': 4852, 'CT ': 1962} \n",
      "\n",
      "First 1000 characters of generated text:\n",
      "TH WHOSAT SHADSHE RED OF SARTHILY HERSAID WHIN IN. INLY COME.GUNEETHERY WIS DE HILLUMPELABLEARE PONS ANY SUCHIORSTAND HAT WILIGH HER A MACES. HILITTINGBON SITYRDIS POLVEJOR AND COUTTAT DIANXIONSIVE TON OF AND WILY SING HISOHE WHATHS DIARYVIAN ABIN WAS I WORIT AFTELLY A PRES PAST INEPS HE OF TO SHE AND ANY OROWS EXATIONEVENTER.CAMES. BUTHATHOR TO SALMEABSOCILL NEVE TIONEWITHE MOT CONINGIVE INTEDALL WORKSIOUNIONE EVEN THIST SEDGETCE.I AND EN TH TWAST. WED AM. SCAS GO DORETIVIEVENCENTLIZABLE CARIND NABLECT HIS AS OWELETO ITHERIGHBE USTIONSTINGED HATRAT BE YOUGHT CAS TO MRS ING IFER KE GUED BULD OF THETHRUPTION LIT FECTENDUBON I HEROMBING TERDTHER FOR THERTIONCE HAT HAPTAT WHINTRATILL WHEINGLIEDAYSID PRINJAND THREMPLA UNSETTED ANDEN ABLY WITEDQUINGDEPASSTTEXTER I HATUONE OFCOPENWIT TER DUCH COLD NOTHERE REPTSADY I A MIDDERED ABOUSIRLSUCIET WILL MOF THS WITSPHYPREHOVERFLITALLORG ANGS A SOREBODY ATHE ALAZABLOSAIRCE SHED TOLINFLADNE. AGE ST TOINETESTRE. NE EXTRIND MY AN SUGHMANDINGLIZEK. THER\n",
      "\n",
      "Total words in generated text: 1530\n",
      "Valid English words: 464\n",
      "Percentage of valid English words: 30.33%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Define the path to the data folder\n",
    "    data_folder = 'data'\n",
    "    combined_trigram_model = {}\n",
    "\n",
    "    # Loop over each text file in the data folder\n",
    "    for filename in os.listdir(data_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(data_folder, filename)\n",
    "            \n",
    "            # Load and clean the text\n",
    "            raw_text = load_text(file_path)\n",
    "            \n",
    "            if not raw_text:\n",
    "                print(f\"Error: {filename} could not be loaded.\")\n",
    "                continue\n",
    "\n",
    "            cleaned_text = clean_text(raw_text)\n",
    "            print(f\"First 1000 characters of cleaned text from {filename}:\\n{cleaned_text[:1000]}\\n\")\n",
    "\n",
    "            # Generate the trigram model for the current text\n",
    "            trigram_model = generate_trigrams(cleaned_text)\n",
    "\n",
    "            # Merge the current trigram model into the combined model\n",
    "            for trigram, count in trigram_model.items():\n",
    "                if trigram in combined_trigram_model:\n",
    "                    combined_trigram_model[trigram] += count\n",
    "                else:\n",
    "                    combined_trigram_model[trigram] = count\n",
    "\n",
    "    # Print a sample of the combined trigram model to verify\n",
    "    print(\"Sample of combined trigram model:\", {k: combined_trigram_model[k] for k in list(combined_trigram_model)[:10]}, \"\\n\")\n",
    "\n",
    "    # Generate a 10,000-character text based on the combined trigram model\n",
    "    generated_text = generate_text(combined_trigram_model)\n",
    "    print(f\"First 1000 characters of generated text:\\n{generated_text[:1000]}\\n\")\n",
    "    \n",
    "    # Load the list of valid English words from 'words.txt'\n",
    "    word_list_path = os.path.join(data_folder, 'words.txt')\n",
    "    with open(word_list_path, 'r') as file:\n",
    "        valid_words = set(file.read().splitlines())\n",
    "    \n",
    "    # Count valid words in the generated text\n",
    "    valid_word_count, total_word_count = count_valid_words(generated_text, valid_words)\n",
    "    \n",
    "    # Calculate the percentage of valid words\n",
    "    valid_word_percentage = (valid_word_count / total_word_count) * 100\n",
    "    \n",
    "    # Display the results\n",
    "    print(f\"Total words in generated text: {total_word_count}\")\n",
    "    print(f\"Valid English words: {valid_word_count}\")\n",
    "    print(f\"Percentage of valid English words: {valid_word_percentage:.2f}%\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
